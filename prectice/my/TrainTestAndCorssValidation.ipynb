{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65657cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "#simple example of a machine learning pipeline using the Naïve Bayes classification algorithm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# Generate dummy dataset\n",
    "X = np.random.rand(100, 5) # 100 samples, 5 features\n",
    "y = np.random.randint(0, 2, 100) # Binary target variable (0 or 1)\n",
    "\n",
    "# Splitting the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=42)\n",
    "# Create a Naïve Bayes model\n",
    "model = GaussianNB()\n",
    "# Train the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4fa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold CV Average Accuracy: 0.6498336576486097\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Load dataset\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "# Select features and target, handling missing values\n",
    "X = df[['age', 'fare']].fillna(df[['age', 'fare']].mean())\n",
    "y = df['survived']\n",
    "# Convert to DataFrame to use .iloc[]\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "# Define K-Fold (5 splits)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Initialize model\n",
    "model = LogisticRegression()\n",
    "# Store accuracy scores\n",
    "accuracy_scores = []\n",
    "# Perform K-Fold CV\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] # Now X is a DataFrame\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index] # Now y is a Series\n",
    "\n",
    "     # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    " # Predict and evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(acc)\n",
    "# Print average accuracy\n",
    "print(\"K-Fold CV Average Accuracy:\", np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4111413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV Average Accuracy: 0.6565656565656566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "# Initialize LOOCV\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Store accuracy scores\n",
    "loo_scores = []\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    " X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    " y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    " # Train model\n",
    " model.fit(X_train, y_train)\n",
    "\n",
    " # Predict and evaluate\n",
    " y_pred = model.predict(X_test)\n",
    " loo_scores.append(accuracy_score(y_test, y_pred))\n",
    "# Print average accuracy\n",
    "print(\"LOOCV Average Accuracy:\", np.mean(loo_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df6bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Will this person buy the product? Yes\n"
     ]
    }
   ],
   "source": [
    "# Supervised Learning (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Input data (features): Age and Income\n",
    "X = [[25, 50000], [30, 60000], [22, 45000], [35, 85000], [40, 100000], [28, 58000]]\n",
    "\n",
    "# Output data (labels): 0 = No, 1 = Yes\n",
    "y = [0, 1, 0, 1, 1, 1]\n",
    "\n",
    "# Split data: 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Try predicting new example\n",
    "new_person = [[27, 55000]]\n",
    "prediction = model.predict(new_person)\n",
    "print(\"Will this person buy the product?\", \"Yes\" if prediction[0] == 1 else \"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "090994fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 4. Classification\n",
    "# Support Vector Machine\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "y = (y == 0).astype(int) # Convert to binary classification problem\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "random_state=42)\n",
    "# Train SVM model with RBF kernel\n",
    "svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Sent to Linear Regression Model ===\n",
      "x_train shape: (120, 1)\n",
      "x_train sample:\n",
      " [[1. ]\n",
      " [1.5]\n",
      " [4.4]\n",
      " [1.6]\n",
      " [1.3]]\n",
      "y_train shape: (120,)\n",
      "y_train sample: [0.2 0.4 1.4 0.2 0.2]\n",
      "============================================\n",
      "Predictions: [1.58555194 0.34583706 2.49467619 1.50290428 1.62687577 0.2631894\n",
      " 1.13098982 1.75084726 1.50290428 1.2549613  1.75084726 0.22186557\n",
      " 0.18054174 0.2631894  0.2631894  1.58555194 2.04011406 1.2549613\n",
      " 1.50290428 1.9574664  0.30451323 1.6681996  0.30451323 1.9574664\n",
      " 2.28805704 1.79217109 2.04011406 2.08143789 0.22186557 0.30451323]\n",
      "Mean Squared Error: 0.045604284097661846\n",
      "R² Score (Accuracy-like): 0.9282562958836972\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENT LINEAR REGRESSION\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error ,r2_score\n",
    "\n",
    "# Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, 2].reshape(-1, 1)  # Use petal length as the feature\n",
    "y = iris.data[:, 3]  # Use petal width as the target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the data being sent to the model\n",
    "print(\"=== Data Sent to Linear Regression Model ===\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_train sample:\\n\", x_train[:5])\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_train sample:\", y_train[:5])\n",
    "print(\"============================================\")\n",
    "\n",
    "# Create and train the Linear Regression model\n",
    "LR = LinearRegression()\n",
    "ModelLR = LR.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "PredictionLR = ModelLR.predict(x_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predictions:\", PredictionLR)\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test, PredictionLR)\n",
    "r2 = r2_score(y_test, PredictionLR)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R² Score (Accuracy-like):\", r2)\n",
    "\n",
    "# How to interpret R²:\n",
    "# 1.0 = perfect prediction\n",
    "\n",
    "# 0.0 = model predicts no better than the mean\n",
    "\n",
    "# < 0 = model is worse than just guessing the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b77f338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
